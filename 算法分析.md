# 第二章 算法分析

## 2.1 数学基础

本书将会使用以下4个定义：

**定义2.1**

如果存在正常数c和$n_0$使得当$N\geq n_0$时$T(N)\leq cf(N)$,则记为$T(N)=O(f(N))$。

**定义2.2**

如果存在正常数c和$n_0$使得当$N\geq n_0$时$T(N)\geq cg(N)$,则记为$T(N)=\Omega (g(N))$。

**定义2.3**

$T(N)=\Theta (h(N))$当且仅当$T(N)=O(h(N))$和$T(N)=\Omega(h(N))$。

**定义2.4**

如果对每一正常数c都存在常数$n_0$使得当$N>n_0$时$T(N)<cp(N)$，则$T(N)=o(p(N))$。有时也可以说，如果$T(N)=O(p(N))$且$T(N)\neq \Theta(p(N))$，则$T(N)=o(p(N))$。

一般来说T(N)=O(f(N))，则说f(N)是T(N)的**上界**；$T(N)=\Omega(f(N))$，则说f(N)是T(N)的**下界**。

**计算法则**

**法则1**

如果$T_1(N)=O(f(N))$且$T_2(N)=O(g(N))$，那么
(a) $T_1(N)+T_2(N)=O(f(N)+g(N))$，或非正式max(O(f(N)),O(g(N)))。
(b) $T_1(N)* T_2(N)=O(f(N) * g(N))$

**法则2**

如果T(N)是一个k次多项式，则$T(N)=\Theta (N^k)$。

**法则3**

对任意常数k，$log^k N=O(N)$。所以对数增长很缓慢.

## 2.2 模型

为了分析算法的性能，建立了一个理想的计算机模型。

## 2.3 要分析的问题

**运行时间**

**输入大小** 定义两个函数$T_avg(N)$和$T_worst(N)$。显然$T_{avg}(N) \leq T_{worst} (N)$。

### 最大子序列和问题

[参考文献1](http://blog.csdn.net/hcbbt/article/details/10454947)
[参考文献2](http://blog.csdn.net/zhaobryant/article/details/38537457)

## 2.4 运行时间计算

### 2.4.2 一般法则

**法则1 ————for循环**

一个for循环的运行时间至多是该for循环内部**语句运行时间**乘以**迭代次数**。

**法则2 ————嵌套的for循环**

循环的运行时间为**循环内部语句运行时间**乘以**所有for循环**的大小的乘积。

**法则3 ————顺序语句**

将各条语句**求和**即可。

**法则4 ————if/else语句**

```Java
if(condition)
  S1
else
  S2
```

一个if/else语句的运行时间为从不超过判断的运行时间在**加**上**S1和S2**运行时间**长者**的总运行时间。

> 分析的基本策略:**从内向外展开**；如果有**方法调用**，**首先分析调用**；如果有**递归**，存在几种选择，比如该递归实际上是一个for循环。

### 2.4.3 最大子序列和问题求解

[几个算法](http://blog.csdn.net/zhaobryant/article/details/38537457)

### 2.4.4 运行时间的对数

> 对数运行时间的规律：如果一个算法将其大小划分为其**一部分(1/K)**,则算法是O(logN)的，如果只是减少了一个常数量，则算法为O(N)的。

**折半查找**

**欧几里得算法**

**定理2.1** 如果M > N，则M mod N < M/2

所以迭代次数**至多**为2logN=O(logN)。

**幂运算**

计算$X^N$是使用N-1乘法自乘。如果使用递归算法，如果N为偶数，$X^N=X^{N/2}*X^{N/2}$；如果N为奇数，$X^N=X^{N/2}*X^{N/2}*X$

```java
1     public static long pow(long x,int n)
2     {
3       if(n == 0)
4          return 1;
5       if(n == 1)
6          return x;
7       if(isEven(n))
8          return pow(x*x,n/2);
9       else
10         return pow(x*x,n/2)*x;
11    }
```

不一样的写法
```java
8a      return pow(pow(x,2),n/2);
8b      return pow(pow(x,n/2),2);
8c      return pow(x,n/2)*pow(x,n/2);
```

其中8a和8b都将引起无限循环调用，当N是2时，会出现错误。而8c会影响程序效率，递归调用两个一样的递归，其**运行时间不再是O(logN)**。

### 2.4.5 检验你的分析

验证程序的一个方法是：根据分析的运行时间，然后按倍数增大N，观察是否与预期一致。

另一个技巧是：对一个O(f(N))的程序，对N的某个范围计算比值**T(N)/f(N)**。如果如何预期，则收敛为一个常数；如果f(N)估计过大，则收敛为0；付过f(N)估计过低，则值发散。

### 2.4.6 分析结果的准确性

有时**分析过大**，有两种情况：①需要进一步细化分析；②可能是平均运行时间小鱼最坏情形的运行时间，然而不能改变最坏的界，**有时候分析平均运行时间是很复杂的**。


# 小结

在本书中看到希尔排序(第七章)和一个保持不想交集的算法(第八章)，都是难以分析的。

一类有趣的算法分析是**下界分析**。在第七章我们将会证明任何**通过比较来进行排序**在最坏情形下只需要**O(NlogN)次比较**。

在进行一个几百位数字进行幂运算时，使用递归算法将会大量减少乘法的次数。

# 练习

2.1 按增长率排列下列函数：N，$\sqrt N$，$N^1.5$，$N^2$，$N\log N$，$N\log \log N$,$N\log^2{N}$，$N\log{N}^2$，2/N，$2^N$，$2^{N/2}$，37，$N^2 \log N$，$N^3$。指出哪些函数以相同的增长率增长。

答：

$2^N$ > $2^{N/2}$ > $N^3$ > $N^2 \log N$ > $N^2$ > $N^1.5$ > $N\log^2{N}$ > $N\log{N}^2$ $\approx$ $N\log N$ > $N\log \log N$ > N > $\sqrt N$ > 37 > 2/N。
其中$N\log{N}^2$和$N\log N$以相同的增长率增长。

2.2 设$T_1 (N)=O(f(N))$和$T_2 (N)=O(f(N))$。下列等式哪些成立？

a. $T_1 (N) + T_2 (N)=O(f(N))$
b. $T_1 (N) - T_2 (N)=o(f(N))$
c. $\frac{T_1 (N)}{T_2 (N)}=O(1)$
d. $T_1 (N)=O(T_2 (N))$

答：
a、c、d。

2.3 哪个函数增长得更快：NlogN，还是$N^{1+	\epsilon\sqrt log(N)}$

答：

$N^{1+	\epsilon\sqrt log(N)}$更快
证明：
利用洛必达法则计算

2.4 证明对任意常数k，$log^k N=o(N)$

答：

由洛必达法则，$\lim_{N \rightarrow +\infty} \frac{log^k N}{N}=\lim_{N \rightarrow +\infty} k\frac{log^{k-1} N}{Nln2}$

最后得$\lim_{N \rightarrow +\infty} \frac{log^k N}{N}=\frac{N！}{ln^2 2}=0$

得证

2.5 求两个函数f(N)和g(N)使得既不f(N)=O(g(N))，又不g(N)=O(f(N))

答:。。。

2.6

答：
a.$N^2$美元
b.O(loglog(D))

2.7
答：
a:
(1) O(N)
(2) O($N^2$)
(3) O($N^3$)
(4) $T=\sum_{i=1}^n i=O(N^2)$
(5) O($N^5$)
(6) O($N^4$)
2.15

答：

使用二分查找，如果mid $A_i>i，则high=mid-1$；mid $A_i<i，则low=mid+1$。时间为O(logN)。
