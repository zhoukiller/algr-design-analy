# 第五章 散列

散列表的实现叫**散列**。散列适用于以常数平均时间插入删除和查找的技术。但是关于排序信息操作不会得到支持。

## 5.1 一般想法

通常查找是对项的某个部分进行，这部分称为**关键字**。

项可以有一个串(可以作为关键字)和其他一些数据项组成。我们把表的大小设置为TableSize，表从0到TableSize - 1变化。

每个关键字被映射到0到TableSize-1的表中的某个位置。这个映射称为**散列函数**。
由于表的元素有限，所以需要解决当两个关键字映射到同一个位置的情况，这种情况称为**冲突**。

## 5.2 散列函数

好的办法通常是保证表的大小为素数。当关键字是随机输入时，散列函数不仅计算起来简单而且关键字的分配也很均匀。
通常，关键之是**字符串**。

散列函数方法：

1. 将字符串中的字符ASCII码(或Unicode码)值加起来。当表很大时，函数不会很好分配关键字。例如，关键字8个字符长，8*127=1016,显然会造成分配不均匀。

2. 利用字母加空格共27个字符，只考虑前三个字符，则27^3为最大空间位置。但是由于英文不是随机分布的，所以会有很多空间被浪费。

3. $\sum_{i=0}^{KeySize -1} Key[KeySize - i - 1]*37^i$，并将结果限制在一定范围，该函数散列分布会很好。该函数利用Horner法则计算$h_k=k_0+37k_1+37^2k_2$。该函数运行溢出。可能引进负的数，在末尾有附加的测试。

有时候不需要计算所有的字符串，当关键字过长时，散列函数计算会花费过多时间，可以选择计算前n项字符。

接下来需要解决当一个元素插入时与一个已经插入元素散列到同一个值得情况，需要将该冲突解决。这里讨论两个最简单的冲突解决方法：分离链接法和开放定址法。

## 5.3 分离链接法

该方法将散列到同一值得所有元素保存到一个表中。可以使用标准库的实现方法(双向链表)，如果空间很小，则避免使用双向链表。

为执行一次查找，使用散列函数来确定遍历链表的位置，然后再在链表中执行一次查找。为执行insert，我们需要检查相应的链表该元素是否已经处在适当的位置(如果允许重复插入，通常还有留出一个用于统计频率的域)。如果该元素是新元素，则插入到链表的前端，因为：新插入的元素往往会在不久的将来被访问。

```
public class SeparateChainingHashTable<AnyType>
{
  public SeparateChainingHashTable()

  public SeparateChainingHashTable(int size)

  public void insert()

  public void remove(AnyType x)

  public boolean contains(AnyType x)

  public void makeEmpty()

  private static final int DEFAULT_TABLE_SIZE=101;

  private List<AnyType> [] theLists;
  private int currentSize;

  private void rehash()

  private int myhash(AnyType x)

  private static int nextPrime(int n)

  private static boolean isPrime(int n)

}
```

在Java中这样的对象必须提供适当的equals方法和返回一个int型量的hashCode方法。

在插入例程中，当元素已经存在时，不做任何操作；否则将其放入链表中。链表可以被一个二叉查找树或者另一个散列表替代。

定义散列表的**装填因子**$\lambda$为散列表中的元素个数对该表的大小的比。

遍历散列表的时间是计算散列函数值的常数时间加上遍历链表所用的时间。

被搜索的链表包含匹配的节点在加上0或更多的其他节点。

在N个元素的散列表以及M个链表中的**其他节点**的期望个数为$(N-1)/M=\lambda - 1/M$，该值基本上为$\lambda$，因为假设M是大的。

平均来看，一半的**其他节点**被搜索到，在结合匹配节点，得到$1+\lambda/2$个节点的平均查找代价。

这个分析指出，散列表的大小不重要，**装填因子才重要**。

分离链表散列法的一般法则是让$\lambda\approx1$。如果超过了1，则通过rehash方法扩大散列表的大小。

##5.4 不用链表的散列表

由于分配新单元需要时间，所以算法的速度有所减慢，同事该算法还要求对第二种数据结构的实现。

另一种不用链表解决冲突的方法是，当冲突发生时按照一定规则，直到找到空的单元为止。单元$h_0(x),h_1(x),h_2(x),\cdots$背相继选中,$h_i(x)=(hash(x)+f(i)) mod TableSize$,且f(0)=0。函数f是解除冲突的方法。

对于不使用分离链接的散列表来说，装填因子应该低于0.5。这样的表叫做**探测散列表**。

### 5.4.1 线性探测法

函数f为i的线性函数，典型情形为f(i)=i。

当表较空，占据的单元会形成一些区块，其结果成为**一次聚集**。

可以证明，使用线性探测的预期探测次数对于插入和不成功的查找来说大约为$\frac{1}{2}(1+1/(1-\lambda)^2)$，对于成功的查找来说是$\frac{1}{2}(1+1/(1-\lambda))$

如果聚集不算问题，可以假设有一个很大的散列表，并设每次探测和前面的探测无关。随机冲突解决方法而言，是成立的，并且当$\lambda$不是非常接近1时也是合理的。

由于空单元占比为$1-\lambda$，预计要探测的单元数为$1/(1-\lambda)$。

一次成功查找的探测次数等于该特定元素插入时所需要的探测次数。当一个元素被插入时，可以看成一次不成功的查找的结果。

因此，可以使用一次不成功的查找的开销来计算一次成功查找的平均开销。

可以使用积分来计算插入时间平均值的方法来估计平均值，得到：

$I(\lambda)=\frac{1}{\lambda} \int_0^{\lambda} \frac{1}{1-x}=\frac{1}{\lambda}ln \frac{1}{1-\lambda}$

这个公式显然要优于线性探测的对应公式。

可以得出当$\lambda=0.5$时，插入操作平均只需要2.5次探测，而成功的查找只需要1.5次探测

### 5.4.2 平方探测法

该方法中$f(i)=i^2$。

对于线性探测，让散列表几乎填满会影响表的性能。对于平方探测更糟糕：一旦表被填充超过一半，当表的大小不是素数时甚至可能在表填充到一半之前，就找不到空的单元了。这是因为最多有表的一半可以用作解决冲突的备选位置。

**定理 5.1**

> 如果使用平方探测，且表的大小是素数，那么当表至少有一半是空的时候，总能插入一个新的元素。

证明：

领表的大小为TableSize是大于3的(奇)素数。前$\lceil TableSize/2 \rceil$个备选位置(包括初始位置$h_0(x)$)是互异的。$h(x)+i^2(\pmod {TableSize})$和$h(x)+j^2(\pmod {TableSize})$是这些位置中的其中两个，其中$0\leq i,j \leq \lfloor TableSize/2 \rfloor$。假设这两个位置相同但是$i \neq j$,于是

$h(x)+i^2 = h(x)+j^2 (\pmod {TableSize})$
$i^2=j^2 \pmod {TableSize}$
$(i-j)(i+j) \pmod {TableSize}$

由于TableSize为素数，所以(i-j)(\pmod {TableSize})=0或(i+j)(\pmod {TableSize})=0。既然i和j是互异的，那么第一个就是不可能的，但是i和j的定义范围，所以第二个也不可能。所以前$\lceil TableSize/2 \rceil$个备选位置是互异的。如果最多有$\lfloor TableSize/2 \rfloor$个位置被使用，则总能找到空单元。

如果仅比一般多一个，插入操作可能都是失败的，表的大小是素数也很重要。如果表不是素数，备选单元的个数可能会锐减。

探测散列表中的标准三层操作不能执行，因为相应的单元可能**已经引起过冲突**，元素绕过了存储在了别处。因此探测散列表需要**懒惰删除**。

HashEntry引用数组的每一项是下面三种情况之一：

1. null
2. 非null，且该项是活动的(isActive为true)
3. 非null，且该项被标记删除(isActive为false)

contains(x)调用私有方法isActive和findPos。这里的findPos实施对冲突的解决。在insert方法中，确保散列表至少为元素个数的两倍大，这样平方探测解决方案总能实现。标记删除的元素还留着表中，这可能引起表提前过满。

若x已经存在，则不做任何操作。如果装填因子超过0.5，则表是满的，需要将散列表至少扩大为元素的两倍。这个过程称为**再散列**。

同样地，平方探测法会导致**二次散列**。下面的技术会排除这个问题，不过要付出计算另一个附加的散列函数的代价。

### 5.4.3 双散列

对于双散列，一种流行的选择是$f(i)=i*hash_2(x)$。

该公式表明将会将应用到x并在距离$hash_2(x)，2hash_2(x)，\cdots$等处探测。$hash_2(x)$选择不好将会是灾难性的。函数一定不能算出0值。此外，保证所有单元可以被探测到也很重要。诸如$hash_2(x)=R - (x \pmod R)$这样会起到不错的作用，其中R为小于TableSize的素数。

如果表的大小不是素数，那么备选单元就可能提前用完。然而，如果双散列正确实现，模拟表明，预期探测的次数几乎和随机冲突解决方法的情形相同。不过计算串的散列值，会很耗时。

## 5.5 再散列

对于使用平方探测的开放定址散列法，如果散列表太满，操作的运行时间会消耗过长，且插入操作可能会失败。一种解决方法是建立另外一个大约两倍大的表，扫描整个原始散列表，计算每个元素新的散列值，并将其插入到新表中。

整个操作叫做**再散列**。其运行时间为O(N)，由于不是经常发生，所以实际效果没有那么差。因为最后得再散列之前已经存在N/2次insert，所以添加到每个插入上的花费是常数开销。

如果作为交互系统的一部分运行，其插入引起在散列的不幸用户将会感到速度减慢。

再散列有三种策略：

1. 表满到一半就再散列。
2. 极端的情况是插入失败才再散列。
3. 途中策略：散列表到达某一个装填因子时再散列。

第三种策略可能是最好的策略，只要该阈值设置得当。

## 5.6 标准库中的散列表

标准库包含Set和Map的散列表实现，即HashSet和HashMap类。HashSet类中的项(或关键字)必须提供equals方法和hashCode方法。HashSet和HashMap采用分离链接散列实现的。

如果一个表项是否有序查看不重要，那么可以使用散列表。

在4.8节单词变换例子中，存在三种映射：

1. 关键字为单词的长度，而关键字的值是长为该单词长度的**所有单词**的集合。
2. 关键字是一个代表，关键字的值是具有该代表的**所有单词**的集合。
3. 关键字是一个单词，关键字的值是与该单词**只有一个字母不同的所有单词**的集合。

HashMap的性能常常优于TreeMap的性能。在HashMap或TreeMap可以接受的情况下，使用接口类型Map进行**变量声明**,将TreeMap的实例变成HashMap的实例并进行计时测试。

为了能被插入到HashSet或HashMap中，定义了equals和hashCode方法。因为Hash算法最耗时的计算是计算hash值，所以String中的hashCode方法都存储hashCode值。这样在第一次访问后的访问都不需要计算hash值。这种方法叫做**闪存散列代码**，本质是**时空交换**。

闪存散列代码有效，是因为String类是不能改变的；否则，hashCode可能就会变化，hashCode就得重新计算。

闪存散列代码另一个有用的情况是**再散列**。在再散列期间，String对象的hashCode值都在散列时被闪存过。

## 5.7 可扩散列

当数据量太大无法装进内存的情况。这个时候主要的时间消耗在磁盘存取上。

假设有N个记录需要存储；N的值随时间变化。最多将M个记录放到一个**区块**中，我们暂时设M=4。

当散列表过满时，必须执行再散列，需要O(N)次磁盘访问。

解决这个问题的一个选择叫做**可扩散列**，使用两次磁盘访问执行一次查找。插入也需要很少的磁盘操作。

想到B树具有深度$O(log_{M/2} N)$，当M增大，树的深度减小。理论上，深度可以为1，此时只需要一次磁盘访问，因为根节点可能都放在内存中。但是有太多的分支，导致确定是哪个分支需要大量计算。如果可以减少这个计算，那么就可以获得一个不错的方案。

假设数据由6bit组成。每个叶子最多为M个元素。而树的根由一个链组成，每个链元素确定数据的前两个比特，这样可以指明数据在哪个树叶中。

用D表示根使用的比特数，也称为**目录**。目录的项数为$2^D$。$d_L$为树叶元素**共有**的最高比特位数。$d_L \leq D$。

插入时，就需要树叶的分裂和目录的更新，目录的D不够时，就需要增加位数。

这个简单的方法提供了对大型数据库insert操作和操作操作的快速存取时间。

接下来考虑**细节**：

1.

例如：原来一片满树叶只需要00就可以指定，但是当插入0002 00 时，这样需要相同的前导比特位为D+2=4。这时需要多次目录分裂。

就是当一个树叶的元素有多以**D+1**个前导比特位相同时，需要多次目录分裂。

2.

重复关键字可能存在，此时该算法**无效**。

所以这些比特的完全随机是**很重要的**。

**可扩散列的性能分析**

> 假设：位模式是均匀分布的。

结论：

树叶的期望个数： $(N/M)log_2 e$。

平均树叶满的程度： ln2=0.69。

目录的期望大小： $O(N^{1+1/M}/M)$。

所以M很小时，目录大小就会很大，以致无法放进内存。

为了解决目录过大的问题，就需要将树叶的元素包含数据的链。
这样将会导致第二次磁盘访问。

## 小结

相比于二叉查找树，散列表无法查证**有序**元素。而且查找树的O(logN)也不一定比O(1)大很多，因为二叉查找树不需要计算散列函数的乘法和除法。

如果不需要**有序**信息，及对**数据输入是否是排好序**不知情，则可以选择散列表。

应用：

1. 编译器中的声明的变量，这种结构叫做**符号表**。

2. 图论中具有实际名字的节点，可以使用散列表；这样可以避免有序对二叉查找树的性能破坏。

3. 游戏程序的位置：可以通过计算基于位置的散列函数，这样同样地位置通过简单的变换来避免**重复计算**。

4. 在线拼写程序，可以将整个词典预先散列。因为此时字母排序并不重要。

对于**字谜问题**，可以使用散列别来改进。
